{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44c46cec-7f8a-4cf4-a8b2-6e5dcf54883c",
   "metadata": {},
   "source": [
    "## 0. Getting setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c92707b0-1341-44d1-911d-302614158dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.2.0+cu121\n",
      "torchvision version: 0.17.0+cu121\n",
      "[INFO] Coudnl't find torchinfo... installing it\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "\n",
    "print(f\"torch version: {torch.__version__}\")\n",
    "print(f\"torchvision version: {torchvision.__version__}\")\n",
    "\n",
    "try:\n",
    "    from torchinfo import summary\n",
    "except:\n",
    "    print(\"[INFO] Coudnl't find torchinfo... installing it\")\n",
    "    !pip install -q torchinfo\n",
    "    from torchinfo import summary\n",
    "\n",
    "try:\n",
    "    from going_modular import data_setup, engine\n",
    "except:\n",
    "    print(\"[INFO] Couldn't find going_modular scripts...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d9c7242-3f89-4d4a-bc48-6e235d1d56d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8227e79e-6f6e-42a7-b8ce-f83256ecb1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seeds(seed: int=42):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ad0c67-d005-464d-9607-c058665b4a29",
   "metadata": {},
   "source": [
    "# 1. Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "437cec2b-c9b8-41e3-a912-1cea3e600942",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Did not find data\\pizza_steak_sushi directory, creating one...\n",
      "[INFO] Downloading pizza_steak_sushi.zip from https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip...\n",
      "[INFO] Unzipping pizza_steak_sushi.zip data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('data/pizza_steak_sushi')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "\n",
    "def download_data(source: str, \n",
    "                  destination: str,\n",
    "                  remove_source: bool = True) -> Path:\n",
    "    # Setup path to data folder\n",
    "    data_path = Path(\"data/\")\n",
    "    image_path = data_path / destination\n",
    "\n",
    "    # If the image folder doesn't exist, download it and prepare it... \n",
    "    if image_path.is_dir():\n",
    "        print(f\"[INFO] {image_path} directory exists, skipping download.\")\n",
    "    else:\n",
    "        print(f\"[INFO] Did not find {image_path} directory, creating one...\")\n",
    "        image_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Download pizza, steak, sushi data\n",
    "        target_file = Path(source).name\n",
    "        with open(data_path / target_file, \"wb\") as f:\n",
    "            request = requests.get(source)\n",
    "            print(f\"[INFO] Downloading {target_file} from {source}...\")\n",
    "            f.write(request.content)\n",
    "\n",
    "        # Unzip pizza, steak, sushi data\n",
    "        with zipfile.ZipFile(data_path / target_file, \"r\") as zip_ref:\n",
    "            print(f\"[INFO] Unzipping {target_file} data...\") \n",
    "            zip_ref.extractall(image_path)\n",
    "\n",
    "        # Remove .zip file\n",
    "        if remove_source:\n",
    "            os.remove(data_path / target_file)\n",
    "    \n",
    "    return image_path\n",
    "\n",
    "image_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
    "                           destination=\"pizza_steak_sushi\")\n",
    "image_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4767b40c-6e55-4ad9-b4da-c89931c6ab4f",
   "metadata": {},
   "source": [
    "# 2. Create Datasets and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9886549-5d88-4b05-b7d0-1b97747184a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manually created transforms: Compose(\n",
      "    Resize(size=(224, 224), interpolation=bicubic, max_size=None, antialias=True)\n",
      "    CenterCrop(size=(224, 224))\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.226])\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<torch.utils.data.dataloader.DataLoader at 0x1d515fe4590>,\n",
       " <torch.utils.data.dataloader.DataLoader at 0x1d579639690>,\n",
       " ['pizza', 'steak', 'sushi'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dir = image_path / \"train\"\n",
    "test_dir = image_path / \"test\"\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.226])\n",
    "\n",
    "manual_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    normalize])\n",
    "print(f\"Manually created transforms: {manual_transforms}\")\n",
    "\n",
    "train_dataloader, test_dataloader, class_names = data_setup.create_dataloaders(\n",
    "    train_dir=train_dir,\n",
    "    test_dir=test_dir,\n",
    "    transform=manual_transforms,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "train_dataloader, test_dataloader, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36d4acdb-ca65-4c1d-88f6-fa66969ba73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kajetan\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Kajetan\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to C:\\Users\\Kajetan/.cache\\torch\\hub\\checkpoints\\efficientnet_b0_rwightman-7f5810bc.pth\n",
      "100%|██████████| 20.5M/20.5M [00:02<00:00, 10.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.efficientnet_b0(pretrained=True).to(device) # for torchvision < 13\n",
    "# weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT for torchvision > 0.13\n",
    "# model = torchvision.models.efficientnet_b0(weights=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9bb4272-ce88-4ab3-b157-844491a4b64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all base layers\n",
    "for param in model.features.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "set_seeds()\n",
    "\n",
    "model.classfier = torch.nn.Sequential(\n",
    "    nn.Dropout(p=0.2, inplace=True),\n",
    "    nn.Linear(in_features=1280,\n",
    "              out_features=len(class_names),\n",
    "              bias=True).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17b9671c-029f-4997-bbc4-50ba90046006",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchinfo import summary\n",
    "\n",
    "# summary(model,\n",
    "#         input_size=(32, 3, 224, 224),\n",
    "#         verbose=0,\n",
    "#         col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "#         col_width=20,\n",
    "#         row_settings=[\"var_names\"]\n",
    "#        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee14d08-234e-4bd4-82f5-6824db3ed403",
   "metadata": {},
   "source": [
    "# 4. Train model and track results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "00c1650f-7d65-4f4c-aa2c-a6b7f1f623f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fba57228-b69d-4148-b760-13a1dc95f86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import wandb\n",
    "except:\n",
    "    !pip install wandb\n",
    "    import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "296f66e0-0632-4baf-96a5-4b4e0ecb277b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "from tqdm.auto import tqdm\n",
    "from going_modular.engine import train_step, test_step\n",
    "\n",
    "def train(model: torch.nn.Module,\n",
    "          train_dataloader: torch.utils.data.DataLoader,\n",
    "          test_dataloader: torch.utils.data.DataLoader,\n",
    "          optimizer: torch.optim.Optimizer,\n",
    "          criterion: torch.nn.Module,\n",
    "          epochs: int,\n",
    "          device: torch.device,\n",
    "         wandb_project_name: str = None,\n",
    "         wandb_run_name: str = None) -> Dict[str, List]:\n",
    "    \n",
    "    if wandb_project_name is not None:\n",
    "        wandb.init(project=wandb_project_name, name=wandb_project_name)\n",
    "    \n",
    "    results = {\"train_loss\": [],\n",
    "               \"test_loss\": [],\n",
    "               \"train_acc\": [],\n",
    "               \"test_acc\": []\n",
    "              }\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        train_loss, train_acc = train_step(model=model,\n",
    "                                           dataloader=test_dataloader,\n",
    "                                           loss_fn=criterion,\n",
    "                                           optimizer=optimizer,\n",
    "                                           device=device)\n",
    "        test_loss, test_acc = test_step(model=model,\n",
    "                                         dataloader=test_dataloader,\n",
    "                                         loss_fn=criterion,\n",
    "                                         device=device)\n",
    "        print(\n",
    "            f\"Epoch: {epoch+1} | \"\n",
    "            f\"train_loss: {train_loss:.4f} | \"\n",
    "            f\"test_loss: {test_loss:.4f} | \"\n",
    "            f\"train_acc: {train_acc:.4f} | \"\n",
    "            f\"test_acc: {test_acc:.4f} | \"\n",
    "        )\n",
    "\n",
    "        if wandb_project_name is not None:\n",
    "            wandb.log({\"train_loss\": train_loss,\n",
    "            \"test_loss\": test_loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"test_acc\": test_acc})\n",
    "            \n",
    "        results[\"train_loss\"].append(train_loss)\n",
    "        results[\"test_loss\"].append(test_loss)\n",
    "        results[\"train_acc\"].append(train_acc)\n",
    "        results[\"test_acc\"].append(test_acc)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4efd42d9-a7bc-46ce-9cff-3d941334ef36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:dn9pquwx) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>test_acc</td><td>▁▃▅▅▆▇████</td></tr><tr><td>test_loss</td><td>█▆▅▄▄▃▂▂▁▁</td></tr><tr><td>train_acc</td><td>▁▅▅▆▆▆▆▆▇█</td></tr><tr><td>train_loss</td><td>█▆▅▄▃▃▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>test_acc</td><td>0.63731</td></tr><tr><td>test_loss</td><td>1.47138</td></tr><tr><td>train_acc</td><td>0.64678</td></tr><tr><td>train_loss</td><td>1.33514</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">torch_experiment_track</strong> at: <a href='https://wandb.ai/frackowiak_kajetan/torch_experiment_track/runs/dn9pquwx' target=\"_blank\">https://wandb.ai/frackowiak_kajetan/torch_experiment_track/runs/dn9pquwx</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240407_140018-dn9pquwx\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:dn9pquwx). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "550b358736194cd98ed22b5e896e6153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011288888888925108, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Kajetan\\Documents\\pytorch_deep_learning\\wandb\\run-20240407_141257-tasft5lv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/frackowiak_kajetan/torch_experiment_track/runs/tasft5lv' target=\"_blank\">torch_experiment_track</a></strong> to <a href='https://wandb.ai/frackowiak_kajetan/torch_experiment_track' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/frackowiak_kajetan/torch_experiment_track' target=\"_blank\">https://wandb.ai/frackowiak_kajetan/torch_experiment_track</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/frackowiak_kajetan/torch_experiment_track/runs/tasft5lv' target=\"_blank\">https://wandb.ai/frackowiak_kajetan/torch_experiment_track/runs/tasft5lv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02774dbb052d4b38a166b05ba4630c64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 1.2614 | test_loss: 1.4073 | train_acc: 0.5350 | test_acc: 0.6686 | \n",
      "Epoch: 2 | train_loss: 1.1727 | test_loss: 1.3568 | train_acc: 0.6989 | test_acc: 0.6790 | \n",
      "Epoch: 3 | train_loss: 1.2345 | test_loss: 1.3337 | train_acc: 0.6572 | test_acc: 0.6790 | \n",
      "Epoch: 4 | train_loss: 1.2629 | test_loss: 1.2984 | train_acc: 0.6373 | test_acc: 0.6894 | \n",
      "Epoch: 5 | train_loss: 1.1265 | test_loss: 1.2734 | train_acc: 0.6070 | test_acc: 0.6998 | \n",
      "Epoch: 6 | train_loss: 1.1345 | test_loss: 1.2212 | train_acc: 0.6364 | test_acc: 0.6799 | \n",
      "Epoch: 7 | train_loss: 1.0738 | test_loss: 1.1959 | train_acc: 0.7311 | test_acc: 0.6799 | \n",
      "Epoch: 8 | train_loss: 1.0301 | test_loss: 1.1768 | train_acc: 0.6278 | test_acc: 0.7008 | \n",
      "Epoch: 9 | train_loss: 0.9603 | test_loss: 1.1387 | train_acc: 0.6799 | test_acc: 0.7008 | \n",
      "Epoch: 10 | train_loss: 0.9565 | test_loss: 1.1047 | train_acc: 0.7311 | test_acc: 0.7112 | \n",
      "Epoch: 11 | train_loss: 0.9266 | test_loss: 1.0724 | train_acc: 0.6477 | test_acc: 0.7519 | \n",
      "Epoch: 12 | train_loss: 0.9139 | test_loss: 1.0597 | train_acc: 0.7405 | test_acc: 0.7519 | \n",
      "Epoch: 13 | train_loss: 1.0348 | test_loss: 1.0434 | train_acc: 0.7197 | test_acc: 0.7112 | \n",
      "Epoch: 14 | train_loss: 0.9098 | test_loss: 1.0340 | train_acc: 0.7604 | test_acc: 0.7216 | \n",
      "Epoch: 15 | train_loss: 0.8175 | test_loss: 1.0015 | train_acc: 0.7102 | test_acc: 0.7320 | \n",
      "Epoch: 16 | train_loss: 0.8664 | test_loss: 1.0088 | train_acc: 0.7405 | test_acc: 0.7320 | \n",
      "Epoch: 17 | train_loss: 0.8615 | test_loss: 0.9937 | train_acc: 0.7102 | test_acc: 0.7320 | \n",
      "Epoch: 18 | train_loss: 0.7502 | test_loss: 0.9653 | train_acc: 0.8125 | test_acc: 0.7623 | \n",
      "Epoch: 19 | train_loss: 0.7974 | test_loss: 0.9343 | train_acc: 0.6903 | test_acc: 0.7623 | \n",
      "Epoch: 20 | train_loss: 0.7428 | test_loss: 0.9163 | train_acc: 0.7718 | test_acc: 0.7623 | \n"
     ]
    }
   ],
   "source": [
    "set_seeds()\n",
    "model0 = train(model=model,\n",
    "                train_dataloader=train_dataloader,\n",
    "                test_dataloader=test_dataloader,\n",
    "                optimizer=optimizer,\n",
    "                criterion=criterion,\n",
    "                epochs=20,\n",
    "                device=device,\n",
    "               wandb_project_name=\"torch_experiment_track\",\n",
    "               wandb_run_name=\"torch_experiment_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f999ef38-b2d3-4686-aad6-163ad425bc01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] data\\pizza_steak_sushi directory exists, skipping download.\n",
      "[INFO] Did not find data\\pizza_steak_sushi_20_percent directory, creating one...\n",
      "[INFO] Downloading pizza_steak_sushi_20_percent.zip from https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip...\n",
      "[INFO] Unzipping pizza_steak_sushi_20_percent.zip data...\n"
     ]
    }
   ],
   "source": [
    "data_10_percent_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
    "                                     destination=\"pizza_steak_sushi\")\n",
    "\n",
    "data_20_percent_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip\",\n",
    "                                     destination=\"pizza_steak_sushi_20_percent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "51e13267-7f0d-4c27-ad6a-c53e43f95706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_directory 10%: data\\pizza_steak_sushi\\train\n",
      "Training_directory 20%: data\\pizza_steak_sushi_20_percent\\train\n",
      "Testing_directory data\\pizza_steak_sushi\\test\n"
     ]
    }
   ],
   "source": [
    "train_dir_10_percent = data_10_percent_path / \"train\"\n",
    "train_dir_20_percent = data_20_percent_path / \"train\"\n",
    "\n",
    "test_dir = data_10_percent_path / \"test\"\n",
    "\n",
    "print(f\"Training_directory 10%: {train_dir_10_percent}\")\n",
    "print(f\"Training_directory 20%: {train_dir_20_percent}\")\n",
    "print(f\"Testing_directory {test_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b8e9b656-62bd-4a92-91bd-03123893bb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "simple_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b688ccb2-116f-4f05-ad5d-99edb7953532",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of batches of size 32 in 10 percent training data: 8\n",
      "Number of batches of size 32 in 20 percent training data: 15\n",
      "Number of batches of size 32 in testing data: 3 (all experiments will use the same test data)\n",
      "Number of classes 3, class_names ['pizza', 'steak', 'sushi']\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader_10_percent, test_dataloader, class_names = data_setup.create_dataloaders(\n",
    "    train_dir=train_dir_10_percent,\n",
    "    test_dir=test_dir,\n",
    "    transform=simple_transform,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "train_dataloader_20_percent, test_dataloader, class_names = data_setup.create_dataloaders(\n",
    "    train_dir=train_dir_20_percent,\n",
    "    test_dir=test_dir,\n",
    "    transform=simple_transform,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "print(f\"Number of batches of size {BATCH_SIZE} in 10 percent training data: {len(train_dataloader_10_percent)}\")\n",
    "print(f\"Number of batches of size {BATCH_SIZE} in 20 percent training data: {len(train_dataloader_20_percent)}\")\n",
    "print(f\"Number of batches of size {BATCH_SIZE} in testing data: {len(test_dataloader)} (all experiments will use the same test data)\")\n",
    "print(f\"Number of classes {len(class_names)}, class_names {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "97d85667-5ecf-41dc-ad16-55f3b117ce6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of in_features to final layer of EfficientNetB2; 1408\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torchinfo import summary\n",
    "\n",
    "effnetb2 = torchvision.models.efficientnet_b2(pretrained=True).to(device)\n",
    "\n",
    "# summary(model=effnetb2,\n",
    "#         input_size=(32, 3, 224, 224),\n",
    "#         col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "#         col_width=20,\n",
    "#         row_settings=[\"var_names\"]\n",
    "# )\n",
    "\n",
    "print(f\"Number of in_features to final layer of EfficientNetB2; {len(effnetb2.classifier.state_dict()['1.weight'][0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6e904cb0-cd4b-46df-b188-6002b63a5bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torch import nn\n",
    "\n",
    "OUT_FEATURES = len(class_names)\n",
    "\n",
    "def create_effnetb0():\n",
    "    model = torchvision.models.efficientnet_b0(pretrained=True).to(device)\n",
    "\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    set_seeds()\n",
    "\n",
    "    model.classifier = nn.Sequential(\n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Linear(in_features=1280, out_features=OUT_FEATURES)\n",
    "    ).to(device)\n",
    "\n",
    "    model.name = \"effnetb0\"\n",
    "    print(f\"[INFO] Created new {model.name} model.\")\n",
    "    return model\n",
    "\n",
    "def create_effnetb2():\n",
    "    model = torchvision.models.efficientnet_b2(pretrained=True).to(device)\n",
    "\n",
    "    for param in model.features.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    set_seeds()\n",
    "\n",
    "    model.classfier = nn.Sequential(\n",
    "        nn.Dropout(p=0.3),\n",
    "        nn.Linear(in_features=1408, out_features=OUT_FEATURES)\n",
    "    ).to(device)\n",
    "\n",
    "    model.name = \"effnetb2\"\n",
    "    print(f\"[INFO] Created new {model.name} model.\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "eab32e82-c9ea-4a78-a988-7cc0cecaed0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created new effnetb0 model.\n"
     ]
    }
   ],
   "source": [
    "effnetb0 = create_effnetb0()\n",
    "\n",
    "# summary(model=effnetb0,\n",
    "#         input_size=(32, 3, 224, 224),\n",
    "#         col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "#         col_width=20,\n",
    "#         row_settings=[\"var_names\"]\n",
    "#        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ed7e7302-7375-49af-b521-ef8c8e75e406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created new effnetb2 model.\n"
     ]
    }
   ],
   "source": [
    "effnetb2 = create_effnetb2()\n",
    "\n",
    "# summary(model=effnetb2,\n",
    "#         input_size=(32, 3, 224, 224),\n",
    "#         col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "#         col_width=20,\n",
    "#         row_settings=[\"var_names\"]\n",
    "#        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7943c6a3-db5c-4915-a789-e203c9c4dd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = [5, 10]\n",
    "models = [\"effnetb0\", \"effnetb2\"]\n",
    "train_dataloaders = {\"data_10_percent\": train_dataloader_10_percent,\n",
    "                     \"data_20_percent\": train_dataloader_20_percent}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "73326153-398f-4825-a40f-5f45ad0c4dd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# from going_modular.utils import save_model\n",
    "\n",
    "# set_seeds(seed=42)\n",
    "\n",
    "# experiment_number = 0\n",
    "\n",
    "# for dataloader_name, train_dataloader in train_dataloaders.items():\n",
    "#     for epochs in num_epochs:\n",
    "#         for model_name in models:\n",
    "#             experiment_number += 1\n",
    "#             print(f\"[INFO] Experiment number: {experiment_number}\")\n",
    "#             print(f\"[INFO] Model: {model_name}\")\n",
    "#             print(f\"[INFO] DataLoader: {dataloader_name}\")\n",
    "#             print(f\"[INFO] Number of epochs: {epochs}\")\n",
    "\n",
    "#             if model_name == \"effnetb0\":\n",
    "#                 model = create_effnetb0()\n",
    "#             else:\n",
    "#                 model = create_effnetb2()\n",
    "\n",
    "#             criterion = nn.CrossEntropyLoss()\n",
    "#             optimizer = torch.optim.Adam(params=model.parameters(), lr=1e-3)\n",
    "\n",
    "#             train(model=model,\n",
    "#                 train_dataloader=test_dataloader,\n",
    "#                 test_dataloader=test_dataloader,\n",
    "#                 optimizer=optimizer,\n",
    "#                 criterion=criterion,\n",
    "#                 epochs=epochs,\n",
    "#                 device=device,\n",
    "#                 wandb_project_name=model_name,\n",
    "#                 wandb_run_name=model_name)\n",
    "\n",
    "#             save_filepath = f\"07_{model_name}_{dataloader_name}_{epochs}_epochs.pth\"\n",
    "#             save_model(model=model,\n",
    "#                         target_dir=\"models\",\n",
    "#                         model_name=save_filepath)\n",
    "#             print(\"-\"*50+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "6446c961-422a-4a97-b57e-6452690dff73",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:bz1gbrgo) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.030 MB uploaded\\r'), FloatProgress(value=0.04479561601937108, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">torch_experiment_track</strong> at: <a href='https://wandb.ai/frackowiak_kajetan/torch_experiment_track/runs/bz1gbrgo' target=\"_blank\">https://wandb.ai/frackowiak_kajetan/torch_experiment_track/runs/bz1gbrgo</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240407_161409-bz1gbrgo\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:bz1gbrgo). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f29e45af91f74e27967b99fabe11e80c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011288888888925108, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Kajetan\\Documents\\pytorch_deep_learning\\wandb\\run-20240407_162547-o074b6rf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/frackowiak_kajetan/effnetb0v1/runs/o074b6rf' target=\"_blank\">effnetb0v1</a></strong> to <a href='https://wandb.ai/frackowiak_kajetan/effnetb0v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/frackowiak_kajetan/effnetb0v1' target=\"_blank\">https://wandb.ai/frackowiak_kajetan/effnetb0v1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/frackowiak_kajetan/effnetb0v1/runs/o074b6rf' target=\"_blank\">https://wandb.ai/frackowiak_kajetan/effnetb0v1/runs/o074b6rf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de103c64fe94cd7b7b1c8f343eeca7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 | train_loss: 2.4582 | test_loss: 0.9101 | train_acc: 0.0521 | test_acc: 0.5388 | \n",
      "Epoch: 2 | train_loss: 0.4887 | test_loss: 0.8324 | train_acc: 0.8854 | test_acc: 0.6146 | \n",
      "Epoch: 3 | train_loss: 1.1438 | test_loss: 0.6522 | train_acc: 0.6250 | test_acc: 0.7083 | \n",
      "Epoch: 4 | train_loss: 1.0308 | test_loss: 0.4101 | train_acc: 0.6278 | test_acc: 0.8854 | \n",
      "Epoch: 5 | train_loss: 0.7541 | test_loss: 0.3495 | train_acc: 0.6600 | test_acc: 0.9489 | \n",
      "Epoch: 6 | train_loss: 0.5150 | test_loss: 0.2837 | train_acc: 0.7746 | test_acc: 0.9176 | \n",
      "Epoch: 7 | train_loss: 0.3674 | test_loss: 0.2477 | train_acc: 0.9167 | test_acc: 0.9375 | \n",
      "Epoch: 8 | train_loss: 0.3842 | test_loss: 0.2143 | train_acc: 0.8333 | test_acc: 0.9479 | \n",
      "Epoch: 9 | train_loss: 0.4335 | test_loss: 0.1539 | train_acc: 0.8021 | test_acc: 0.9896 | \n",
      "Epoch: 10 | train_loss: 0.3646 | test_loss: 0.1408 | train_acc: 0.8438 | test_acc: 0.9896 | \n",
      "Epoch: 11 | train_loss: 0.3158 | test_loss: 0.1405 | train_acc: 0.9479 | test_acc: 1.0000 | \n",
      "Epoch: 12 | train_loss: 0.2655 | test_loss: 0.1157 | train_acc: 0.9792 | test_acc: 0.9896 | \n",
      "Epoch: 13 | train_loss: 0.2418 | test_loss: 0.0994 | train_acc: 0.9167 | test_acc: 0.9896 | \n",
      "Epoch: 14 | train_loss: 0.2238 | test_loss: 0.0909 | train_acc: 0.9479 | test_acc: 0.9896 | \n",
      "Epoch: 15 | train_loss: 0.2220 | test_loss: 0.0836 | train_acc: 0.9583 | test_acc: 1.0000 | \n",
      "Epoch: 16 | train_loss: 0.2237 | test_loss: 0.0763 | train_acc: 0.9583 | test_acc: 1.0000 | \n",
      "Epoch: 17 | train_loss: 0.1909 | test_loss: 0.0720 | train_acc: 0.9688 | test_acc: 1.0000 | \n",
      "Epoch: 18 | train_loss: 0.1915 | test_loss: 0.0661 | train_acc: 0.9896 | test_acc: 1.0000 | \n",
      "Epoch: 19 | train_loss: 0.1793 | test_loss: 0.0614 | train_acc: 0.9792 | test_acc: 1.0000 | \n",
      "Epoch: 20 | train_loss: 0.1820 | test_loss: 0.0573 | train_acc: 0.9792 | test_acc: 1.0000 | \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'train_loss': [2.45819620291392,\n",
       "  0.4886525273323059,\n",
       "  1.1438140620787938,\n",
       "  1.0307846864064534,\n",
       "  0.7541138132413229,\n",
       "  0.514960765838623,\n",
       "  0.36741480231285095,\n",
       "  0.3841744164625804,\n",
       "  0.43349965910116833,\n",
       "  0.3646253744761149,\n",
       "  0.3157743116219838,\n",
       "  0.26548127830028534,\n",
       "  0.24175597230593363,\n",
       "  0.22375581910212836,\n",
       "  0.22200021396080652,\n",
       "  0.22368882099787393,\n",
       "  0.1908637434244156,\n",
       "  0.19146337111790976,\n",
       "  0.17925211787223816,\n",
       "  0.18196836113929749],\n",
       " 'test_loss': [0.9101417859395345,\n",
       "  0.8324042558670044,\n",
       "  0.6521581063667933,\n",
       "  0.4101025735338529,\n",
       "  0.3495146880547206,\n",
       "  0.28372859954833984,\n",
       "  0.24766658246517181,\n",
       "  0.21431847661733627,\n",
       "  0.1539208466808001,\n",
       "  0.14081821093956629,\n",
       "  0.1405228798588117,\n",
       "  0.11567142729957898,\n",
       "  0.09942262743910153,\n",
       "  0.09087116892139117,\n",
       "  0.08355570336182912,\n",
       "  0.07634762426217397,\n",
       "  0.07204516232013702,\n",
       "  0.06607562613983949,\n",
       "  0.06140480128427347,\n",
       "  0.05734508919219176],\n",
       " 'train_acc': [0.052083333333333336,\n",
       "  0.8854166666666666,\n",
       "  0.625,\n",
       "  0.6278409090909091,\n",
       "  0.6600378787878788,\n",
       "  0.774621212121212,\n",
       "  0.9166666666666666,\n",
       "  0.8333333333333334,\n",
       "  0.8020833333333334,\n",
       "  0.84375,\n",
       "  0.9479166666666666,\n",
       "  0.9791666666666666,\n",
       "  0.9166666666666666,\n",
       "  0.9479166666666666,\n",
       "  0.9583333333333334,\n",
       "  0.9583333333333334,\n",
       "  0.96875,\n",
       "  0.9895833333333334,\n",
       "  0.9791666666666666,\n",
       "  0.9791666666666666],\n",
       " 'test_acc': [0.5388257575757576,\n",
       "  0.6145833333333334,\n",
       "  0.7083333333333334,\n",
       "  0.8854166666666666,\n",
       "  0.9488636363636364,\n",
       "  0.9176136363636364,\n",
       "  0.9375,\n",
       "  0.9479166666666666,\n",
       "  0.9895833333333334,\n",
       "  0.9895833333333334,\n",
       "  1.0,\n",
       "  0.9895833333333334,\n",
       "  0.9895833333333334,\n",
       "  0.9895833333333334,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0]}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(model=effnetb0,\n",
    "      train_dataloader=train_dataloader,\n",
    "      test_dataloader=test_dataloader,\n",
    "      optimizer=torch.optim.Adam(params=effnetb0.parameters(), lr=1e-2),\n",
    "      criterion=criterion,\n",
    "      epochs=20,\n",
    "      device=device,\n",
    "      wandb_project_name=\"effnetb0v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "86a85814-c933-4015-bbe6-62550358edc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Model 'effnetb0V1' saced successfully to 'models/effnetb0V1.pth'\n"
     ]
    }
   ],
   "source": [
    "def save_model(model, model_name):\n",
    "    file_path = f\"models/{model_name}.pth\"\n",
    "\n",
    "    torch.save({\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'model_name': model_name\n",
    "    }, file_path)\n",
    "\n",
    "    print(f\"[INFO] Model '{model_name}' saced successfully to '{file_path}'\")\n",
    "\n",
    "save_model(effnetb0, \"effnetb0V1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "09f028c5-7ca2-4139-98ca-690c15419343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Created new effnetb0 model.\n",
      "[INFO] Model 'effnetb0V1' loaded successfully\n"
     ]
    }
   ],
   "source": [
    "def load_model(filepath):\n",
    "    checkpoint = torch.load(filepath)\n",
    "\n",
    "    if checkpoint['model_name'] == \"effnetb0V1\":\n",
    "        model = create_effnetb0()\n",
    "    elif checkpoint['model_name'] == \"effnetb0V2\":\n",
    "        model = create_effnetb2()\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported model name\")\n",
    "\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    print(f\"[INFO] Model '{checkpoint['model_name']}' loaded successfully\")\n",
    "    return model\n",
    "\n",
    "effnetV1_model_path = \"models/effnetb0V1.pth\"\n",
    "effnetV1_loaded = load_model(effnetV1_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "398ab7a5-5093-43d4-bd33-cacb6aaef8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effnetb0V1_loaded feature extractor model size: 15 MB\n"
     ]
    }
   ],
   "source": [
    "# Check the model file size\n",
    "from pathlib import Path\n",
    "\n",
    "effnetb0_model_size = Path(effnetV1_model_path).stat().st_size // (1024*1024)\n",
    "print(f\"Effnetb0V1_loaded feature extractor model size: {effnetb0_model_size} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "9f3be56c-5b2e-41d3-887d-fe3ba67bdcfb",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Size should be int or sequence. Got <class 'pathlib.WindowsPath'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[254], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Iterate through random test image paths, make predictions on them, and plot them\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_path \u001b[38;5;129;01min\u001b[39;00m test_image_path_sample:\n\u001b[1;32m---> 17\u001b[0m     \u001b[43mpred_and_plot_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meffnetV1_loaded\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mclass_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimage_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\pytorch_deep_learning\\going_modular\\predictions.py:26\u001b[0m, in \u001b[0;36mpred_and_plot_image\u001b[1;34m(model, class_names, image_path, image_size, transform, device)\u001b[0m\n\u001b[0;32m     23\u001b[0m     image_transform \u001b[38;5;241m=\u001b[39m transform\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     25\u001b[0m     image_transform \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m---> 26\u001b[0m         \u001b[43mtransforms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mResize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m     27\u001b[0m         transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[0;32m     28\u001b[0m         transforms\u001b[38;5;241m.\u001b[39mNormalize(\n\u001b[0;32m     29\u001b[0m             mean\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.485\u001b[39m, \u001b[38;5;241m0.456\u001b[39m, \u001b[38;5;241m0.406\u001b[39m], std\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0.229\u001b[39m, \u001b[38;5;241m0.224\u001b[39m, \u001b[38;5;241m0.225\u001b[39m]\n\u001b[0;32m     30\u001b[0m         ),\n\u001b[0;32m     31\u001b[0m     ]\n\u001b[0;32m     32\u001b[0m )\n\u001b[0;32m     34\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     36\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:334\u001b[0m, in \u001b[0;36mResize.__init__\u001b[1;34m(self, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[0;32m    332\u001b[0m _log_api_usage_once(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(size, (\u001b[38;5;28mint\u001b[39m, Sequence)):\n\u001b[1;32m--> 334\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSize should be int or sequence. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(size)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(size, Sequence) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(size) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m    336\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf size is a sequence, it should have 1 or 2 values\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: Size should be int or sequence. Got <class 'pathlib.WindowsPath'>"
     ]
    }
   ],
   "source": [
    "from going_modular.predictions import pred_and_plot_image\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "# Define the image size\n",
    "image_size = (224, 224)\n",
    "\n",
    "# Get all test image paths from the 20% dataset\n",
    "test_image_path_list = list(Path(data_20_percent_path / \"test\").glob(\"*/*.jpg\"))\n",
    "\n",
    "# Randomly select k number of images\n",
    "num_images_to_plot = 3\n",
    "test_image_path_sample = random.sample(test_image_path_list, k=num_images_to_plot)\n",
    "\n",
    "# Iterate through random test image paths, make predictions on them, and plot them\n",
    "for image_path in test_image_path_sample:\n",
    "    pred_and_plot_image(model=effnetV1_loaded,\n",
    "                        image_path=image_path,\n",
    "                        class_names=class_names,\n",
    "                        image_size=image_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6c54b3-2f6e-4b3b-b783-f09a567560cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e712b2bb-2361-486c-9718-f672b7b60bda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
